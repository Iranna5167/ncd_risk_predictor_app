{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174c973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported and dataset loaded successfully for preprocessing.\n",
      "Initial dataset shape: (100000, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib # For saving/loading preprocessors later\n",
    "\n",
    "# Load the diabetes dataset from the raw folder\n",
    "file_path = '../data/raw/diabetes_prediction_dataset.csv'\n",
    "diabetes_df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Libraries imported and dataset loaded successfully for preprocessing.\")\n",
    "print(f\"Initial dataset shape: {diabetes_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982601c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info (for preprocessing check):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   gender               100000 non-null  object \n",
      " 1   age                  100000 non-null  float64\n",
      " 2   hypertension         100000 non-null  int64  \n",
      " 3   heart_disease        100000 non-null  int64  \n",
      " 4   smoking_history      100000 non-null  object \n",
      " 5   bmi                  100000 non-null  float64\n",
      " 6   HbA1c_level          100000 non-null  float64\n",
      " 7   blood_glucose_level  100000 non-null  int64  \n",
      " 8   diabetes             100000 non-null  int64  \n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 6.9+ MB\n",
      "\n",
      "Missing values check (should be mostly zeros):\n",
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Info (for preprocessing check):\")\n",
    "diabetes_df.info()\n",
    "\n",
    "print(\"\\nMissing values check (should be mostly zeros):\")\n",
    "print(diabetes_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674f2ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable: diabetes\n",
      "Numerical features: ['age', 'hypertension', 'heart_disease', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
      "Categorical features: ['gender', 'smoking_history']\n"
     ]
    }
   ],
   "source": [
    "# Identify target variable(s)\n",
    "# For now, we focus on 'diabetes' as our main target for this model.\n",
    "target = 'diabetes'\n",
    "\n",
    "# Identify features (all columns except the target)\n",
    "features = diabetes_df.drop(columns=[target])\n",
    "\n",
    "# Separate numerical and categorical features for different preprocessing\n",
    "numerical_features = features.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = features.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"Target variable: {target}\")\n",
    "print(f\"Numerical features: {numerical_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67f68e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing transformers defined for numerical (StandardScaler) and categorical (OneHotEncoder) data.\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipeline for numerical features: just scaling\n",
    "# StandardScaler transforms numerical features to have a mean of 0 and a standard deviation of 1.\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Create preprocessing pipeline for categorical features: one-hot encoding\n",
    "# OneHotEncoder converts categorical text labels into a numerical (binary) format\n",
    "# handle_unknown='ignore' prevents errors if an unexpected category appears during prediction\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "print(\"Preprocessing transformers defined for numerical (StandardScaler) and categorical (OneHotEncoder) data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4611de5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer defined to apply specific preprocessing steps to numerical and categorical features.\n"
     ]
    }
   ],
   "source": [
    "# Create a preprocessor using ColumnTransformer to apply different transformations to different columns\n",
    "# 'num' applies numerical_transformer to numerical_features\n",
    "# 'cat' applies categorical_transformer to categorical_features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "print(\"ColumnTransformer defined to apply specific preprocessing steps to numerical and categorical features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "041b45b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets:\n",
      "X_train shape: (80000, 8)\n",
      "X_test shape: (20000, 8)\n",
      "y_train distribution:\n",
      "diabetes\n",
      "0    0.915\n",
      "1    0.085\n",
      "Name: proportion, dtype: float64\n",
      "y_test distribution:\n",
      "diabetes\n",
      "0    0.915\n",
      "1    0.085\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = diabetes_df.drop(columns=[target]) # X contains all features\n",
    "y = diabetes_df[target] # y contains the target variable 'diabetes'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# test_size=0.20 means 20% of the data will be used for testing, 80% for training\n",
    "# random_state ensures reproducibility (you get the same split every time you run it)\n",
    "# stratify=y ensures that the proportion of '0' and '1' in the 'diabetes' target variable\n",
    "# is maintained similarly in both training and testing sets. This is CRUCIAL for imbalanced datasets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Data split into training and testing sets:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"y_test distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ae18ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of 'smoking_history' in the dataset:\n",
      "smoking_history\n",
      "No Info        35816\n",
      "never          35095\n",
      "former          9352\n",
      "current         9286\n",
      "not current     6447\n",
      "ever            4004\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming your main DataFrame is diabetes_df (or health_df for hypertension model)\n",
    "# Make sure this cell runs AFTER you load the dataset in your notebook\n",
    "\n",
    "print(\"Distribution of 'smoking_history' in the dataset:\")\n",
    "print(diabetes_df['smoking_history'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac4feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor or model_pipeline not found or not fitted yet. Please run preceding cells.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
